---
supertitle: Michigan Online
title: Increasing the transparency of ratings and reviews for an online course catalog
permalink: projects/michigan-online/
project_url: https://online.umich.edu/
tagline: I performed comparative analyses, ideated design solutions, and conducted usability tests to increase user satisfaction with online course ratings and reviews.
overview:  Michigan Online is your destination for global, lifelong, and engaged learning with the University of Michigan. For this project, I performed comparative analyses, ideated design solutions, and conducted usability tests to increase user satisfaction with online course ratings and reviews.
where: Michigan Online / 2021
role: As the lead UX designer, I led user research and design while collaborating with a backend developer.
order: 3
featured: false
cover_image: /assets/images/michigan-online/michigan-online--cover.png
read_more: [Twirlmate,Codespec]
published: true
---

<div class="responsive-margin-bottom">
  <img class="d-block w-100" src="/assets/images/michigan-online/michigan-online--before-and-after.png" alt="">
</div>

<div class="responsive-margin-bottom">
  <h2 data-sidebar>The Problem</h2>
  <div>
    <img src="/assets/images/michigan-online/michigan-online--problem.png" class="nhm-card__image object-fit--contain" alt="" />
  </div>
  <p class="">
    Course pages lacked sufficient detail when it came to displaying rating and review information.
  </p>
</div>

<div class="responsive-margin-bottom">
  <h2 data-sidebar>Why It Matters</h2>
  <div>
    <img src="/assets/images/michigan-online/michigan-online--why-it-matters.png" class="w-100" alt="" />
  </div>
  <p class="">
    A well-designed review section contributes to an organization/product's overall <strong>reputation</strong>, and increases consumer <strong>trust</strong> in the quality of their purchase. Visibility into the full array of reviews (not just the most positive ones) also improves the <strong>credibility</strong> of reviews.
  </p>
</div>

<div class="responsive-margin-bottom">
  <h2 data-sidebar>The Goals</h2>
  <img src="/assets/images/michigan-online/michigan-online--after.gif" class="nhm-card__image object-fit--contain" alt="" />
  <p class="">
    To address this challenge, I needed to:
  </p>
  <ol class="pl-2">
    <li class="">
      <p class="">
        Provide a fuller picture of the range of ratings
      </p>
    </li>
    <li class="">
      <p class="">
        Make reviews more browsable
      </p>
    </li>
  </ol>
</div>

<h2 class=" responsive-margin-bottom" data-sidebar>Process</h2>

<div class="responsive-margin-bottom">
  <h3>Competitive Analysis</h3>
  <p class="">
    I first examined how three other online learning sites present ratings and reviews for their content:
  </p> 
  <img src="/assets/images/michigan-online/michigan-online--coursera.png" class="d-block w-100 mb-3" alt="" />
  <img src="/assets/images/michigan-online/michigan-online--udemy.png" class="d-block w-100 mb-3" alt="" />
  <img src="/assets/images/michigan-online/michigan-online--skillshare.png" class="d-block w-100 mb-3" alt="" />
</div>

<div class="responsive-margin-bottom">
  <h3>Prototyping</h3>
  <img src="/assets/images/michigan-online/michigan-online--prototypes.png" class="d-block w-100 mb-3" alt="" />
  <p class="">
    I then explored two approaches: one that kept all rating and review information on the main course page, and one that separated the exploration experience into two pages (offering surface-level information on the main page and a list of full reviews on a different page).
  </p>
  <p class="">
    The first design minimized clicks but increased scrolling on the page as a whole. The second design provided a more progressive exploration of the reviews, but obscured the full set of reviews behind an additional click that some users might miss.
  </p>
</div>

<div class="responsive-margin-bottom">
  <h3>Usability Testing</h3>
  <img src="/assets/images/michigan-online/michigan-online--usability-findings.png" class="nhm-card__image object-fit--contain" alt="" />
  <p class="">
    After that, I conducted 5 usability tests with undergraduate students who were experienced with online learning. Findings included:
  </p> 
  <ul>
    <li>
      <p class="">
        Participants were okay with going to a second page to see all reviews, as it made the main course page less overwhelming.
      </p>
    </li>
    <li>
      <p class="">
        Participants were sometimes unaware that the histogram and star ratings were interactive. One person also suggested displaying the percentage of total ratings each level represented.
      </p>
    </li>
    <li>
      <p class="">
        Some participants expressed interest in knowing more about the people who wrote reviews, in order to determine if the feedback was coming from a person similar to them.
      </p>
    </li>
  </ul>
</div>


<div class="responsive-margin-bottom">
</div>

<div class="responsive-margin-bottom">
  <h3>Final Iteration</h3>
  <p class="">
    In the last iteration of the project, I incorporated user feedback to better communicate each rating's interactivity and proportion.
  </p> 
  <img src="/assets/images/michigan-online/michigan-online--ideal-version.png" class="nhm-card__image object-fit--contain" alt="" />
  <h4>Unexpected Constraint</h4>
  <p class="">
    I experimented with adding more biographical information about each reviewer, but due to data limitaitons I was unable to provide these details. We source our reviews from 3rd party platforms who don't pass that info to us (e.g., Coursera).
  </p> 
</div>

<div class="responsive-margin-bottom ">
  <h2 data-sidebar>The Result</h2>
  <img src="/assets/images/michigan-online/michigan-online--cover.png" class="d-block mw-700 mx-auto nhm-card__image object-fit--contain mt-5" alt="" />
  <p>
  The outcome of this effort was a more interactive, transparent course rating section that allowed prospective learners to explore the full set of reviews for a given learning experience.
  </p>
  <p>
  Now that the design is implemented, I'd like to collect quantitative measurements of user satisfaction, and monitor click-through rates between the course and review pages to guage usage.
  </p>
</div>